#Faceted bar plot: Inspection closure ratio by top 20 cuisine and borough
ggplot(data=inspClosByCuisineBoro, aes(x=cuisine, y=ratio)) +
geom_bar(stat='identity', aes(fill=boro)) +
facet_grid(. ~ boro) +
labs(title='Inspection closure ratio by top 20 cuisine and borough', x='Top 20 cuisine', y='Inspection closure ratio') +
scale_y_continuous(labels = scales::percent) +
scale_fill_brewer(palette = 'Set1') +
theme_bw() +
theme(legend.key=element_blank(), legend.position="bottom") +
coord_flip()
# Find the trend of average scores by month and borough. Graph your result
trendScoreMonth = inspections %>%
group_by(month, boro) %>%
summarise(avg = mean(score))
ggplot(data=trendScoreMonth, aes(x = month, y = avg)) +
geom_freqpoly(stat='identity', aes(color=boro)) +
labs(title='Average score by month and borough',
x='Month',
y='Average score') +
coord_cartesian(xlim = c(1,12), ylim = c(13,18)) +
scale_x_continuous(breaks = 1:12,
labels=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")) +
scale_color_brewer(palette='Set1') +
theme_bw() +
theme(legend.key=element_blank())
# Find the trend of the inspection closure ratio by month and borough. Graph your result.
trendClosures = inspections %>%
group_by(month, boro) %>%
summarise(closures = sum(action == 'closed' | action == 'reclosed'),
inspection = n(),
ratio = closures / inspection)
ggplot(data=trendClosures, aes(x=month, y=ratio)) +
geom_freqpoly(stat='identity', aes(color=boro)) +
labs(title='Inspection closure ratio by month and borough',
x='Month',
y='Inspection closure ratio') +
coord_cartesian(xlim = c(1,12)) +
scale_x_continuous(breaks = 1:12,
labels=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")) +
scale_y_continuous(limits=c(0.005,0.035),
breaks=seq(0,0.035,0.005),
labels=scales::percent) +
scale_color_brewer(palette='Set1') +
theme_bw() +
theme(legend.key=element_blank())
version
library(shiny)
library(ggplot2)
library(dplyr)
library(shinythemes)
library(plotly)
install.packages("tidyverse")
library(tidyverse)
install.packages("tidyverse")
install.packages("plotly")
install.packages("tidyverse", dependencies = TRUE )
install.packages("plotly", dependencies = TRUE )
library(plotly)
devtools::install_github("ropensci/plotly")
insinstall.packages("devtools")
install.packages("devtools")
shiny::runApp('Chipotle_Shiny_Project')
library(DT)
runApp('Chipotle_Shiny_Project')
summary()
chipotles %>% select(., Total_Population) %>% summary()
chipotles %>% filter(., has_chipotle==T) %>% select(., Total_Population) %>% summary()
chipotles %>% filter(., has_chipotle==T) %>% select(., store_count) %>% summary()
chipotles %>% filter(., has_chipotle==F, Total_Population > 110000, Population_Density> 392)
runApp('Chipotle_Shiny_Project')
##################################
#####Visualizing Missing Data#####
##################################
library(VIM) #For the visualization and imputation of missing values.
help(sleep) #Inspecting the mammal sleep dataset.
sleep
summary(sleep) #Summary information for the sleep dataset.
str(sleep)
##################################
#####Visualizing Missing Data#####
##################################
library(VIM) #For the visualization and imputation of missing values.
install.packages("VIM")
##################################
#####Visualizing Missing Data#####
##################################
library(VIM) #For the visualization and imputation of missing values.
help(sleep) #Inspecting the mammal sleep dataset.
sleep
str(sleep)
summary(sleep) #Summary information for the sleep dataset.
#Mean value imputation method 3.
library(caret)
missing.data = data.frame(x1 = 1:20, x2 = c(1:10, rep(NA, 10))) #Recreating dataset.
pre = caret::preProcess(missing.data, method = "medianImpute")
missing.data = predict(pre, missing.data)
missing.data
?caret::preProcess
### Why Caret?
## 1. Maintain the structure of train - predict as other machine learning procedure.
##    This is particularly important when impute for future observation
## 2. Can be collected with other preprocesses, as below:
missing.data = data.frame(x1 = 1:20, x2 = c(1:10, rep(NA, 10))) #Recreating dataset.
pre = preProcess(missing.data, method = c("scale", "medianImpute"))
missing.data = predict(pre, missing.data)
missing.data
missing.data = data.frame(x1 = 1:20, x2 = c(1:10, rep(NA, 10))) #Recreating dataset.
pre = preProcess(missing.data, method = c("center","scale", "medianImpute"))
missing.data = predict(pre, missing.data)
missing.data
## manual scale
missing.data = data.frame(x1 = 1:20, x2 = c(1:10, rep(NA, 10))) #Recreating dataset.
scaled = mapply(FUN = '/',missing.data,sapply(missing.data, function(x) {sd(x,na.rm=T)}))
scaled
##################################
#####Simple Random Imputation#####
##################################
#Recreating a dataset that has missing values.
missing.data = data.frame(x1 = 1:20, x2 = c(1:10, rep(NA, 10)))
missing.data
mean(missing.data$x2, na.rm = TRUE) #Mean of x2 prior to imputation.
sd(missing.data$x2, na.rm = TRUE) #Standard deviation of x2 prior to imputation.
cor(missing.data, use = "complete.obs") #Correlation prior to imputation.
set.seed(0)
imputed.x2 = impute(missing.data$x2, "random") #Simple random imputation using the
#impute() function from the Hmisc package.
imputed.x2
#Mean value imputation method 4.
library(Hmisc) #Load the Harrell miscellaneous library.
##################################
#####Simple Random Imputation#####
##################################
#Recreating a dataset that has missing values.
missing.data = data.frame(x1 = 1:20, x2 = c(1:10, rep(NA, 10)))
missing.data
mean(missing.data$x2, na.rm = TRUE) #Mean of x2 prior to imputation.
sd(missing.data$x2, na.rm = TRUE) #Standard deviation of x2 prior to imputation.
cor(missing.data, use = "complete.obs") #Correlation prior to imputation.
set.seed(0)
imputed.x2 = impute(missing.data$x2, "random") #Simple random imputation using the
#impute() function from the Hmisc package.
imputed.x2
summary(imputed.x2) #Summary information for the imputed variable.
is.imputed(imputed.x2) #Boolean vector indicating imputed values.
missing.data$x2 = imputed.x2 #Replacing the old vector.
mean(missing.data$x2) #Mean of x2 after imputation.
sd(missing.data$x2) #Standard deviation of x2 after imputation.
cor(missing.data, use = "complete.obs") #Correlation afterto imputation.
plot(missing.data) #What are some potential problems with mean value imputation?
#############################
#####K-Nearest Neighbors#####
#############################
#Recreating a dataset that has missing values.
missing.data = data.frame(x1 = 1:20, x2 = c(1:10, rep(NA, 10)))
missing.data
#Imputing using 1NN.
imputed.1nn = kNN(missing.data, k=1)
#Imputing using 1NN.
imputed.1nn = kNN(missing.data, k=1)
### Imputing with caret
### Note: knnImpute with caret::preProcess force normalization
#Imputing using 1NN.
pre.1nn = preProcess(missing.data, method = 'knnImpute', k=1)
imputed.1nn = predict(pre.1nn, missing.data)
#Imputing using 5NN.
pre.5nn = preProcess(missing.data, method = 'knnImpute', k=5)
imputed.5nn = predict(pre.5nn, missing.data)
install.packages("RANN")
library(RANN)
### Imputing with caret
### Note: knnImpute with caret::preProcess force normalization
#Imputing using 1NN.
pre.1nn = preProcess(missing.data, method = 'knnImpute', k=1)
imputed.1nn = predict(pre.1nn, missing.data)
View(imputed.1nn)
##############################################
#####Manual example with the cars dataset#####
##############################################
help(cars)
cars #Investigating the cars dataset.
#Basic numerical EDA for cars dataset.
summary(cars) #Five number summaries.
sapply(cars, sd) #Standard deviations.
cor(cars) #Correlations.
#K-Nearest Neighbors regression on the sleep dataset.
sqrt(nrow(sleep)) #Determining K for the sleep dataset.
#Using 8 nearest neighbors.
pre.8nn = preProcess(sleep, method = 'knnImpute', k=8)
sleep.imputed8NN = predict(pre.8nn, sleep)
summary(sleep) #Summary information for the original sleep dataset.
summary(sleep.imputed8NN[, 1:10]) #Summary information for the imputed sleep dataset.
#K-Nearest Neighbors classification on the iris dataset.
help(iris) #Inspecting the iris measurement dataset.
library(carData)
#####################################################
#####Example using the State Information Dataset#####
#####################################################
help(state.x77)
state.x77 #Investigating the state.x77 dataset.
states = as.data.frame(state.x77) #Forcing the state.x77 dataset to be a dataframe.
#Cleaning up the column names so that there are no spaces.
colnames(states)[4] = "Life.Exp"
colnames(states)[6] = "HS.Grad"
#Creating a population density variable.
states[,9] = (states$Population*1000)/states$Area
colnames(states)[9] = "Density"
#Basic numerical EDA for states dataset.
summary(states)
sapply(states, sd)
cor(states)
#Basic graphical EDA for the states dataset.
plot(states)
#Creating a saturated model (a model with all variables included).
model.saturated = lm(Life.Exp ~ ., data = states)
summary(model.saturated) #Many predictor variables are not significant, yet the
plot(model.saturated) #Assessing the assumptions of the model.
avPlots(model.saturated) #Distinct patterns are indications of good contributions
#We note that Illiteracy has a large VIF, an insignificant p-value in the overall
#regression, and no strong distinct pattern in the added-variable plot. What
#happens when we remove it from the model?
model2 = lm(Life.Exp ~ . - Illiteracy, data = states)
summary(model2) #R^2 adjusted went up, model still significant, etc.
plot(model2) #No overt additional violations.
#model.
anova(model2, model.saturated) #The p-value is quite large, indicating that we
#Let's use the partial F-test to test multiple predictors at once. As compared
#to the saturated model, does the subset of Illiteracy, Area, and Income have
#any effect on our prediction of Life.Exp?
model.full = lm(Life.Exp ~ ., data = states)
model.reduced = lm(Life.Exp ~ . - Illiteracy - Area - Income, data = states)
anova(model.reduced, model.full) #The p-value is quite large; thus, the reduced
#Checking the model summary and assumptions of the reduced model.
summary(model.reduced)
plot(model.reduced)
plot(model.saturated) #Assessing the assumptions of the model.
vif(model.saturated) #Assessing the variance inflation factors for the variables
########################################################
#####Example using Graduate Schools Admissions Data#####
########################################################
GradSchools = read.table("Graduate_Schools.txt")
head(GradSchools)
summary(GradSchools) #Looking at the five number summary information.
sapply(GradSchools, sd) #Looking at the individual standard deviations.
##########################
#####Ridge Regression#####
##########################
library(ISLR)
Hitters = na.omit(Hitters)
##########################
#####Ridge Regression#####
##########################
library(ISLR)
Hitters = na.omit(Hitters)
help(Hitters)
#Need matrices for glmnet() function. Automatically conducts conversions as well
#for factor variables into dummy variables.
x = model.matrix(Salary ~ ., Hitters)[, -1] #Dropping the intercept column.
y = Hitters$Salary
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
#Fitting the ridge regression. Alpha = 0 for ridge regression.
library(glmnet)
ridge.models = glmnet(x, y, alpha = 0, lambda = grid)
dim(coef(ridge.models)) #20 different coefficients, estimated 100 times --
#once each per lambda value.
coef(ridge.models) #Inspecting the various coefficient estimates.
#What do the estimates look like for a smaller value of lambda?
ridge.models$lambda[80] #Lambda = 0.2595.
coef(ridge.models)[, 80] #Estimates not close to 0.
sqrt(sum(coef(ridge.models)[-1, 80]^2)) #L2 norm is 136.8179.
#What do the estimates look like for a larger value of lambda?
ridge.models$lambda[15] #Lambda = 10,235.31.
coef(ridge.models)[, 15] #Most estimates close to 0.
sqrt(sum(coef(ridge.models)[-1, 15]^2)) #L2 norm is 7.07.
#Visualizing the ridge regression shrinkage.
plot(ridge.models, xvar = "lambda", label = TRUE, main = "Ridge Regression")
#Can use the predict() function to obtain ridge regression coefficients for a
#new value of lambda, not necessarily one that was within our grid:
predict(ridge.models, s = 50, type = "coefficients")
#Creating training and testing sets. Here we decide to use a 70-30 split with
#approximately 70% of our data in the training set and 30% of our data in the
#test set.
set.seed(0)
train = sample(1:nrow(x), 7*nrow(x)/10)
test = (-train)
y.test = y[test]
length(train)/nrow(x)
length(y.test)/nrow(x)
#Let's attempt to fit a ridge regression using some arbitrary value of lambda;
#we still have not yet figured out what the best value of lambda should be!
#We will arbitrarily choose 5. We will now use the training set exclusively.
ridge.models.train = glmnet(x[train, ], y[train], alpha = 0, lambda = grid)
ridge.lambda5 = predict(ridge.models.train, s = 5, newx = x[test, ])
mean((ridge.lambda5 - y.test)^2)
#What would happen if we fit a ridge regression with an extremely large value
#of lambda? Essentially, fitting a model with only an intercept:
ridge.largelambda = predict(ridge.models.train, s = 1e10, newx = x[test, ])
mean((ridge.largelambda - y.test)^2)
#Running 10-fold cross validation.
set.seed(0)
cv.ridge.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.out, main = "Ridge Regression\n")
bestlambda.ridge = cv.ridge.out$lambda.min
bestlambda.ridge
log(bestlambda.ridge)
#What is the test MSE associated with this best value of lambda?
ridge.bestlambdatrain = predict(ridge.models.train, s = bestlambda.ridge, newx = x[test, ])
mean((ridge.bestlambdatrain - y.test)^2)
#Here the MSE is lower at approximately 113,173; a further improvement
#on that which we have seen above. With "cv.ridge.out", we can actually access
#the best model from the cross validation without calling "ridge.models.train"
#or "bestlambda.ridge":
ridge.bestlambdatrain = predict.cv.glmnet(cv.ridge.out, s ="lambda.min", newx = x[test, ])
#Here the MSE is lower at approximately 113,173; a further improvement
#on that which we have seen above. With "cv.ridge.out", we can actually access
#the best model from the cross validation without calling "ridge.models.train"
#or "bestlambda.ridge":
ridge.bestlambdatrain = predict(cv.glmnet(cv.ridge.out, s ="lambda.min", newx = x[test, ]))
#Here the MSE is lower at approximately 113,173; a further improvement
#on that which we have seen above. With "cv.ridge.out", we can actually access
#the best model from the cross validation without calling "ridge.models.train"
#or "bestlambda.ridge":
ridge.bestlambdatrain = predict(cv.ridge.out, s ="lambda.min", newx = x[test, ])
mean((ridge.bestlambdatrain - y.test)^2)
### Alternative method with caret
library(caret)
set.seed(0)
train_control = trainControl(method = 'cv', number=10)
tune.grid = expand.grid(lambda = grid, alpha=c(0))
ridge.caret = train(x[train, ], y[train],
method = 'glmnet',
trControl = train_control, tuneGrid = tune.grid)
### Plot the tuning object:
plot(ridge.caret, xTrans=log)
### Predicting with the final model
pred = predict.train(ridge.caret, newdata = x[test,])
mean((pred - y[test])^2)
### Note: there is a "finalModel in ridge.caret. But unfortunately, using it
###       for predicting often results in error.There is some issue with the
###       compactibility of the "predict" function and the model from caret.train
predict(ridge.caret$finalModel, newdata = x[test,])
##########################
#####Lasso Regression#####
##########################
#Fitting the lasso regression. Alpha = 1 for lasso regression.
lasso.models = glmnet(x, y, alpha = 1, lambda = grid)
dim(coef(lasso.models)) #20 different coefficients, estimated 100 times --
#once each per lambda value.
coef(lasso.models) #Inspecting the various coefficient estimates.
#What do the estimates look like for a smaller value of lambda?
lasso.models$lambda[80] #Lambda = 0.2595.
coef(lasso.models)[, 80] #Most estimates not close to 0.
sum(abs(coef(lasso.models)[-1, 80])) #L1 norm is 228.1008.
#What do the estimates look like for a larger value of lambda?
lasso.models$lambda[15] #Lambda = 10,235.31.
coef(lasso.models)[, 15] #Estimates all 0.
sum(abs(coef(lasso.models)[-1, 15])) #L1 norm is essentially 0.
#Visualizing the lasso regression shrinkage.
plot(lasso.models, xvar = "lambda", label = TRUE, main = "Lasso Regression")
#Can use the predict() function to obtain lasso regression coefficients for a
#new value of lambda, not necessarily one that was within our grid:
predict(lasso.models, s = 50, type = "coefficients")
#Let's attempt to fit a lasso regression using some arbitrary value of lambda;
#we still have not yet figured out what the best value of lambda should be!
#We will arbitrarily choose 5. We will now use the training set exclusively.
lasso.models.train = glmnet(x[train, ], y[train], alpha = 1, lambda = grid)
lasso.lambda5 = predict(lasso.models.train, s = 5, newx = x[test, ])
mean((lasso.lambda5 - y.test)^2)
#Running 10-fold cross validation.
set.seed(0)
cv.lasso.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso.out, main = "Lasso Regression\n")
bestlambda.lasso = cv.lasso.out$lambda.min
bestlambda.lasso
log(bestlambda.lasso)
#What is the test MSE associated with this best value of lambda?
lasso.bestlambdatrain = predict(lasso.models.train, s = bestlambda.lasso, newx = x[test, ])
mean((lasso.bestlambdatrain - y.test)^2)
### Exercise: Tune the same lasso model with caret!
# Slide 7
set.seed(0); x = seq(-2, 5, length=100)
noise = rnorm(100); y = 3 + 2*x^2 + 4*noise
plot(x, y)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(MASS)
summary(cats)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
restaurants = read.table("https://s3.amazonaws.com/nycdsabt01/NYC_Restaurants.txt")
plot(restaurants[, -c(1, 6)], col = restaurants$Location)
plot(restaurants[, -c(1, 6)], col = restaurants$Location)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
restaurants = read.table("https://s3.amazonaws.com/nycdsabt01/NYC_Restaurants.txt")
plot(restaurants[, -c(1, 6)], col = restaurants$Location)
plot(restaurants[, -c(1, 6)])
plot(restaurants[, -c(1, 6)], col = restaurants$Location)
plot(restaurants[, -c(1, 6)], color = restaurants$Location)
model.saturated = lm(Price ~ Food + Decor + Service + Location, data = restaurants)
summary(model.saturated)
#The regression equation is: Price = -21.96 + 1.54*Food + 1.91*Decor - 0.003*Service
#- 2.07*West.
#
#When all ratings are 0 and the restaurant is on the East side, the
#average expected price of dinner is about $-21.96 (this does not make sense in
#context of this problem).
#
#As the food rating for a restaurant increases by one
#point, the price increases on average by about $1.54 WHILE HOLDING ALL OTHER
#VARIABLES CONSTANT.
#
#As the decor rating for a restaurant increases by one
#point, the price increases on average by about $1.91 WHILE HOLDING ALL OTHER
#VARIABLES CONSTANT.
#
#As the service rating for a restaurant increases by one
#point, the price decreases on average by about $0.003 WHILE HOLDING ALL OTHER
#VARIABLES CONSTANT.
#
#A restaurant on the west side has an average dinner price that is about $2.07
#cheaper than a meal on the east side WHILE HOLDING ALL OTHER VARIABLES CONSTANT.
#
#All coefficients are significant except for the Service coefficient.
#
#The overall F-statistic is significant so the overall regression is significant.
#
#The RSE is about 5.738, which is an estimate of the average deviation of the
#observations around the regression line.
#
#The adjusted R^2 is 0.6187, meaning that approximately 61.87% of the variation
#in dinner price is accounted for by the variables in our model.
plot(model.saturated)
#No overt deviations from any of the assumptions.
library(car)
vif(model.saturated)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(Slueth2)
library(Slueuth2)
library(Sleuth2)
install.packages("Hmisc")
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
library(ISLR)
attach(Carseats)
#Looking at the variable of interest, Sales.
hist(Sales)
summary(Sales)
#Creating a binary categorical variable High based on the continuous Sales
#variable and adding it to the original data frame.
High = ifelse(Sales <= 8, "No", "Yes")
Carseats = data.frame(Carseats, High)
#Fit a tree to the data; note that we are excluding Sales from the formula.
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
install.packages("tree")
library(tree)
#Plotting the classification tree.
plot(tree.carseats)
Carseats = data.frame(Carseats, High)
#Fit a tree to the data; note that we are excluding Sales from the formula.
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
#Plotting the classification tree.
plot(tree.carseats)
text(tree.carseats, pretty = 0) #Yields category names instead of dummy variables.
#Detailed information for the splits of the classification tree.
tree.carseats
View(tree.carseats)
#Fit a tree to the data; note that we are excluding Sales from the formula.
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
#Plotting the classification tree.
plot(tree.carseats)
text(tree.carseats, pretty = 0) #Yields category names instead of dummy variables.
attach(Carseats)
#Looking at the variable of interest, Sales.
hist(Sales)
summary(Sales)
#Creating a binary categorical variable High based on the continuous Sales
#variable and adding it to the original data frame.
High = ifelse(Sales <= 8, 0, 1)
Carseats = data.frame(Carseats, High)
#Fit a tree to the data; note that we are excluding Sales from the formula.
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
#Plotting the classification tree.
plot(tree.carseats)
text(tree.carseats, pretty = 0) #Yields category names instead of dummy variables.
#Detailed information for the splits of the classification tree.
tree.carseats
#Splitting the data into training and test sets by an 70% - 30% split.
set.seed(0)
train = sample(1:nrow(Carseats), 7*nrow(Carseats)/10) #Training indices.
Carseats.test = Carseats[-train, ] #Test dataset.
High.test = High[-train] #Test response.
#Ftting and visualizing a classification tree to the training data.
tree.carseats = tree(High ~ . - Sales, data = Carseats, subset = train)
plot(tree.carseats)
text(tree.carseats, pretty = 0)
summary(tree.carseats)
housing = read.csv('data/Ames_Real_Estate_data.csv', stringsAsFactors = FALSE)
setwd("~/Downloads/Ames_Iowa_ML_Project")
housing = read.csv('data/Ames_Real_Estate_data.csv', stringsAsFactors = FALSE)
housing = read.csv('./data/Ames_Real_Estate_data.csv', stringsAsFactors = FALSE)
housing = read.csv(file = 'data/Ames_Housing_Price_Data.csv', stringsAsFactors = FALSE)
vif(housing, th= .8)
library(car)
install.packages("car")
install.packages("openxlsx")
install.packages("car")
install.packages("curl")
install.packages("libcurl")
